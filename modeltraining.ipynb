{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import joblib\n",
    "from tkinter import * \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import precision_recall_curve \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_confusion_matrix(y_test, y_pred, modelname):\n",
    "    '''\n",
    "    This function read the true outcome and the predicted outcome,\n",
    "    and draw a confusion matrix of specific model\n",
    "\n",
    "    **Parameters**\n",
    "        y_test: *array*\n",
    "            The real outcome\n",
    "        y_pred: *array*\n",
    "            The predicted outcome\n",
    "        modelname: *str*\n",
    "            The name of model\n",
    "\n",
    "    **Return**\n",
    "        None\n",
    "    '''\n",
    "    # calculate the confusion matrix based on different model \n",
    "    conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "    # plot the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    ax.matshow(conf_matrix, cmap='GnBu', alpha=0.75)\n",
    "    for i in range(conf_matrix.shape[0]):\n",
    "        for j in range(conf_matrix.shape[1]):\n",
    "            ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='large') \n",
    "    plt.xlabel('Predictions', fontsize=10)\n",
    "    plt.ylabel('Actuals', fontsize=10)\n",
    "    plt.title('Confusion Matrix: %s '% modelname, fontsize=12)\n",
    "    fig.savefig('Figure/%s_confusion_matrix.png' % modelname)\n",
    "\n",
    "\n",
    "def ROC_curve(y_test, y_pred_proba, modelname):\n",
    "    '''\n",
    "    This function read the true outcome and the probablity of the positive predicted outcomes,\n",
    "    and draw a ROC curve of specific model\n",
    "\n",
    "    **Parameters**\n",
    "        y_test: *array*\n",
    "            The real outcome\n",
    "        y_pred_proba: *array*\n",
    "            The probablity of the positive predicted outcomes\n",
    "        modelname: *str*\n",
    "            The name of model\n",
    "\n",
    "    **Return**\n",
    "        None\n",
    "    '''\n",
    "    # calculate the false positive rate and true positive rate of model\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:,1])\n",
    "    # calculate the auc value of model\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(fpr, tpr, 'b', label = '%s (AUC = %0.2f)' % (modelname,roc_auc))\n",
    "    #plot the ROC curve and calculate AUC\n",
    "    plt.plot([0, 1], [0, 1],'r--', label='No Skill Classifier')\n",
    "    #plot the 'No Skill Classifier' curve\n",
    "    plt.plot([0, 0, 1], [0, 1, 1], linestyle=':', color='black', label='perfect performance')\n",
    "    #Plot the 'perfect performance' curve\n",
    "    plt.legend(loc = 'lower right')\n",
    "    plt.title('ROC Curve: %s '% modelname)\n",
    "    plt.ylabel('True Positive Rate (sensitivity)')\n",
    "    plt.xlabel('False Positive Rate (1-specificity)')\n",
    "    fig.savefig(\"Figure/%s_ROC_curve.png\" % modelname)\n",
    "    \n",
    "\n",
    "def PR_curve(y_test, y_pred_proba, modelname):\n",
    "    '''\n",
    "    This function read the true outcome and the probablity of the positive predicted outcomes,\n",
    "    and draw a ROC curve of specific model\n",
    "\n",
    "    **Parameters**\n",
    "        y_test: *array*\n",
    "            The real outcome\n",
    "        y_pred_proba: *array*\n",
    "            The probablity of the positive predicted outcomes\n",
    "        modelname: *str*\n",
    "            The name of model\n",
    "\n",
    "    **Return**\n",
    "        None\n",
    "    '''\n",
    "    precision, recall, _= precision_recall_curve(y_test,y_pred_proba[:,1])\n",
    "    #calculate precision and recall\n",
    "    no_skill = len(y_test[y_test==1]) / len(y_test)\n",
    "    fig = plt.figure()\n",
    "    plt.plot(recall, precision, marker='.', label='%s ' % modelname)\n",
    "    #plot PR curve\n",
    "    plt.plot([0, 1], [no_skill, no_skill], linestyle='--', label='No Skill Classifier')\n",
    "    #plot 'No Skill Classifier' curve\n",
    "    plt.xlabel('Recall')\n",
    "    plt.ylabel('Precision')\n",
    "    plt.title('PR Curve: %s '% modelname)\n",
    "    plt.legend()\n",
    "    fig.savefig(\"Figure/%s_PR_curve.png\" % modelname)\n",
    "\n",
    "\n",
    "def Scores(y_test, y_pred, y_pred_proba, modelname):\n",
    "    '''\n",
    "    This function read the true outcome, the predicted outcome \n",
    "    and the probablity of the positive predicted outcomes. \n",
    "    Then, it give back the precison, recall, F1 score and the ROC-AUC score of the model.\n",
    "\n",
    "    **Parameters**\n",
    "        y_test: *array*\n",
    "            The real outcome\n",
    "        y_pred: *array*\n",
    "            The predicted outcomes\n",
    "        y_pred_proba: *array*\n",
    "            The probablity of the positive predicted outcomes\n",
    "        modelname: *str*\n",
    "            The name of model\n",
    "\n",
    "    **Return**\n",
    "        None\n",
    "    '''\n",
    "    print('----------------------------')\n",
    "    print('This is %s'% modelname)\n",
    "    print('Precision: %.3f' % precision_score(y_test, y_pred))\n",
    "    print('Recall: %.3f' % recall_score(y_test, y_pred))\n",
    "    print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))\n",
    "    print('F1 Score: %.3f' % f1_score(y_test, y_pred))\n",
    "    #Calculate the scores by test set and probability estimates provided by the predict_pred\n",
    "    print('ROC-AUC Score: %.3f' % roc_auc_score(y_test, y_pred_proba[:,1]))\n",
    "    #Calculate the ROC-AUC score by test set result probability estimates provided by the predict_proba\n",
    "    return None\n",
    "    \n",
    "\n",
    "def plot_learning_curve(dataset, estimator, modelname):\n",
    "    '''\n",
    "    This function read the dataset and give back its learning curve based on specific model.\n",
    "\n",
    "    **Parameters**\n",
    "        dataset: *dataframe*\n",
    "            The dataframe used for model fitting\n",
    "        estimator: *array*\n",
    "            The fitting model\n",
    "        modelname: *str*\n",
    "            The name of model\n",
    "\n",
    "    **Return**\n",
    "        None\n",
    "    '''\n",
    "    x=dataset.drop(columns='Category')\n",
    "    #Dataset except target\n",
    "    y=dataset['Category']\n",
    "    #Dataset of target\n",
    "    train_sizes, train_scores, test_scores = learning_curve(estimator, x, y)\n",
    "    #Number of samples in training set, score if training set, score of test set\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    #Mean of test set scores\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    #Standard deviation of test scores\n",
    "    fig = plt.figure()\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title('Learning Curve: %s '% modelname, fontsize='small')\n",
    "    plt.grid()\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std, train_scores_mean + train_scores_std, \n",
    "                         alpha=0.1, color=\"b\") \n",
    "    #Plot the learning curve with upper and lower limits of training score\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std, test_scores_mean + test_scores_std, \n",
    "                         alpha=0.1, color=\"r\")\n",
    "    #Plot the learning curve with upper and lower limits of test score\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",label=\"Cross-validation score\")\n",
    "    #Plot learning curve\n",
    "    plt.legend(loc=\"best\")\n",
    "    fig.savefig(\"Figure/%s_Learning_curve.png\" % modelname)\n",
    "\n",
    "\n",
    "def RandomForest(dataset):\n",
    "    '''\n",
    "    This function read a dataset and train it on random forest model.\n",
    "\n",
    "    **Parameters**\n",
    "        dataset: *dataframe*\n",
    "            The addressed dataframe\n",
    "\n",
    "    **Return**\n",
    "        None\n",
    "    '''\n",
    "    X = dataset.drop(['Category'], axis=1)\n",
    "    #Dataset except target\n",
    "    Y = dataset['Category']\n",
    "    #Dataset of target\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, Y, train_size=0.8, test_size=0.2, random_state=100)\n",
    "    #Split data to training set and test set\n",
    "    transfer = StandardScaler()\n",
    "    x_train = transfer.fit_transform(x_train)\n",
    "    x_test = transfer.fit_transform(x_test)\n",
    "    #Feature scaling\n",
    "    rf = RandomForestClassifier(n_estimators=10, n_jobs=2)\n",
    "    rf.fit(x_train,y_train)\n",
    "    #Fit the model to training set\n",
    "    y_pred=rf.predict(x_test)\n",
    "    #Predict the result of test set\n",
    "    y_pred_proba=rf.predict_proba(x_test)\n",
    "    #Predict the result of test set to plot ROC and calculate AUC\n",
    "    joblib.dump(rf, \"Model/rf_model.joblib\" ,compress=1)\n",
    "    plot_confusion_matrix(y_test,y_pred,'RandomForest')\n",
    "    ROC_curve(y_test, y_pred_proba,'RandomForest')\n",
    "    PR_curve(y_test, y_pred_proba,'RandomForest')\n",
    "    plot_learning_curve(dataset,rf,'RandomForest')\n",
    "    Scores(y_test,y_pred,y_pred_proba,'RandomForest')\n",
    "    return y_test, y_pred, y_pred_proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>ALB</th>\n",
       "      <th>ALP</th>\n",
       "      <th>ALT</th>\n",
       "      <th>AST</th>\n",
       "      <th>BIL</th>\n",
       "      <th>CHE</th>\n",
       "      <th>CHOL</th>\n",
       "      <th>CREA</th>\n",
       "      <th>GGT</th>\n",
       "      <th>PROT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>52.500000</td>\n",
       "      <td>7.7</td>\n",
       "      <td>22.1</td>\n",
       "      <td>7.5</td>\n",
       "      <td>6.93</td>\n",
       "      <td>3.23</td>\n",
       "      <td>106.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>70.300000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>24.7</td>\n",
       "      <td>3.9</td>\n",
       "      <td>11.17</td>\n",
       "      <td>4.80</td>\n",
       "      <td>74.0</td>\n",
       "      <td>15.6</td>\n",
       "      <td>76.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>46.9</td>\n",
       "      <td>74.700000</td>\n",
       "      <td>36.2</td>\n",
       "      <td>52.6</td>\n",
       "      <td>6.1</td>\n",
       "      <td>8.84</td>\n",
       "      <td>5.20</td>\n",
       "      <td>86.0</td>\n",
       "      <td>33.2</td>\n",
       "      <td>79.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>43.2</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>30.6</td>\n",
       "      <td>22.6</td>\n",
       "      <td>18.9</td>\n",
       "      <td>7.33</td>\n",
       "      <td>4.74</td>\n",
       "      <td>80.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>75.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "      <td>39.2</td>\n",
       "      <td>74.100000</td>\n",
       "      <td>32.6</td>\n",
       "      <td>24.8</td>\n",
       "      <td>9.6</td>\n",
       "      <td>9.15</td>\n",
       "      <td>4.32</td>\n",
       "      <td>76.0</td>\n",
       "      <td>29.9</td>\n",
       "      <td>68.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>596</th>\n",
       "      <td>1</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>416.600000</td>\n",
       "      <td>5.9</td>\n",
       "      <td>110.3</td>\n",
       "      <td>50.0</td>\n",
       "      <td>5.57</td>\n",
       "      <td>6.30</td>\n",
       "      <td>55.7</td>\n",
       "      <td>650.9</td>\n",
       "      <td>68.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>597</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>102.800000</td>\n",
       "      <td>2.9</td>\n",
       "      <td>44.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.54</td>\n",
       "      <td>3.02</td>\n",
       "      <td>63.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>71.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>598</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>87.300000</td>\n",
       "      <td>3.5</td>\n",
       "      <td>99.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1.66</td>\n",
       "      <td>3.63</td>\n",
       "      <td>66.7</td>\n",
       "      <td>64.2</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>599</th>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>93.220833</td>\n",
       "      <td>39.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3.56</td>\n",
       "      <td>4.20</td>\n",
       "      <td>52.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>1</td>\n",
       "      <td>59</td>\n",
       "      <td>0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>93.220833</td>\n",
       "      <td>100.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.07</td>\n",
       "      <td>5.30</td>\n",
       "      <td>67.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>68.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>601 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Category  Age  Sex   ALB         ALP    ALT    AST   BIL    CHE  CHOL  \\\n",
       "0           0   32    1  38.5   52.500000    7.7   22.1   7.5   6.93  3.23   \n",
       "1           0   32    1  38.5   70.300000   18.0   24.7   3.9  11.17  4.80   \n",
       "2           0   32    1  46.9   74.700000   36.2   52.6   6.1   8.84  5.20   \n",
       "3           0   32    1  43.2   52.000000   30.6   22.6  18.9   7.33  4.74   \n",
       "4           0   32    1  39.2   74.100000   32.6   24.8   9.6   9.15  4.32   \n",
       "..        ...  ...  ...   ...         ...    ...    ...   ...    ...   ...   \n",
       "596         1   62    0  32.0  416.600000    5.9  110.3  50.0   5.57  6.30   \n",
       "597         1   64    0  24.0  102.800000    2.9   44.4  20.0   1.54  3.02   \n",
       "598         1   64    0  29.0   87.300000    3.5   99.0  48.0   1.66  3.63   \n",
       "599         1   46    0  33.0   93.220833   39.0   62.0  20.0   3.56  4.20   \n",
       "600         1   59    0  36.0   93.220833  100.0   80.0  12.0   9.07  5.30   \n",
       "\n",
       "      CREA    GGT  PROT  \n",
       "0    106.0   12.1  69.0  \n",
       "1     74.0   15.6  76.5  \n",
       "2     86.0   33.2  79.3  \n",
       "3     80.0   33.8  75.7  \n",
       "4     76.0   29.9  68.7  \n",
       "..     ...    ...   ...  \n",
       "596   55.7  650.9  68.5  \n",
       "597   63.0   35.9  71.3  \n",
       "598   66.7   64.2  82.0  \n",
       "599   52.0   50.0  71.0  \n",
       "600   67.0   34.0  68.0  \n",
       "\n",
       "[601 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('preprocesseddata1.csv').drop(['Unnamed: 0'], axis=1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Multi class logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression(df)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    X = pd.get_dummies(df.iloc[:, 1:], drop_first=True).values.astype('float')\n",
    "    y = le.fit_transform(df.iloc[:, 0].values).astype('float')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    log_reg = LogisticRegression()\n",
    "    log_reg.fit(X_train, y_train)\n",
    "    y_pred = log_reg.predict(X_test)\n",
    "\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    \n",
    "    return y_test, y_pred, conf_mat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN(df)\n",
    "\n",
    "    le = LabelEncoder()\n",
    "    sc = StandardScaler()\n",
    "\n",
    "    X = pd.get_dummies(df.iloc[:, 1:], drop_first=True).values.astype('float')\n",
    "    y = le.fit_transform(df.iloc[:, 0].values).astype('float')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "    X_train = sc.fit_transform(X_train)\n",
    "    X_test = sc.transform(X_test)\n",
    "\n",
    "    knn_clf = KNeighborsClassifier()\n",
    "    knn_clf.fit(X_train, y_train)\n",
    "    y_pred = knn_clf.predict(X_test) #These are the predicted output values\n",
    "\n",
    "    conf_mat = confusion_matrix(y_test, y_pred)\n",
    "    report = classification_report(y_test, y_pred)\n",
    "    scores = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return y_test, y_pred, conf_mat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "3992ce9eeb352b3e85f750bb43fc68d1f9afd64e6e44a75acff565242ae01ab6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
